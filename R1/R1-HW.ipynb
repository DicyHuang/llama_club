{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install transformers\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **練習 #1**\n",
    "\n",
    "使用 Extractive QA model 以 `pipeline` 做 question-answering 任務：\n",
    "- **給定文本**：the name of repo is bert-base-uncased\n",
    "- **問題目標**：問模型 repo 的名稱\n",
    "- **預期答案**：bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# practice 1 不需要特別指定模型，pipeline 預設載入 distilbert-base-cased-distilled-squad, \n",
    "# 其為 Extractive QA 類摘要模型\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用 Hugging Face 的 text-generation model 與 Sentence Transformers embedding model 實作 QA 檢索聊天機器人。</p>\n",
    "基於提供的資料集，使用 Embedding Cosine Similarity 檢索參考資料，再透過 LLM 生成答案。</p>\n",
    "\n",
    "1. Baseline\n",
    "   - 將 demo 中的資料，替換成我們提供 or 自己的資料集\n",
    "   - 能夠檢索相似資料\n",
    "   - 基於檢索的資料進行回答\n",
    "2. Advanced（Optional）\n",
    "   - Embedding 怎麼儲存？每次都要重新計算嗎？\n",
    "   - 該如何處理太久以前的歷史資料？\n",
    "   - 利用 Gradio or Hugging Face Spaces 部署、分享 Chatbot"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
